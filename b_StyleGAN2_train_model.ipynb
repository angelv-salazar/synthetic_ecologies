{"cells":[{"cell_type":"markdown","metadata":{"id":"qZkTQZc7cMWN"},"source":["# Personalized training: StyleGan2-ADA\n","\n","In this notebook, we will perform transfer learning with StyleGAN2 and custom datasets.\n","\n","This means that we will not train the GAN network on our images from scratch (as it takes around two weeks) but we will use the model already trained on the other images as a starting point. It will reduce the training time to about 10 hours by skipping the early stages where the neural network learns low-level features of images that are almost the same for any type of images."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"WOgc3AOiY6iU"},"outputs":[],"source":["#@title 1. Mount Google Drive\n","#@markdown Access your Google Drive to load images from databases or pre-trained models and save the results.\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6nP8w7IZDpb","cellView":"form"},"outputs":[],"source":["#@title 2. Installation of Libraries\n","#@markdown StyleGAN2-ADA will be installed on your Google Drive to speed up the training process.\n","\n","#@markdown Run this cell. If you have already installed the repository, it will skip the installation process and update the repository directory. If you haven't installed it, it will install all the necessary files.\n","#@markdown You may notice some errors: Ignore them for now, they are compatibility issues that do not affect our work.\n","import os\n","if os.path.isdir(\"/content/drive/MyDrive/colab-sg2-ada-pytorch\"):\n","    %cd \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\"\n","elif os.path.isdir(\"/content/drive/\"):\n","    #install script\n","    %cd \"/content/drive/MyDrive/\"\n","    !mkdir colab-sg2-ada-pytorch\n","    %cd colab-sg2-ada-pytorch\n","    !git clone https://github.com/angelv-salazar/stylegan2-ada-pytorch\n","    %cd stylegan2-ada-pytorch\n","    !mkdir downloads\n","    !mkdir datasets\n","    !mkdir pretrained\n","    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU -O /content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/pretrained/wikiart.pkl\n","else:\n","    !git clone https://github.com/angelv-salazar/stylegan2-ada-pytorch\n","    %cd stylegan2-ada-pytorch\n","    !mkdir downloads\n","    !mkdir datasets\n","    !mkdir pretrained\n","    %cd pretrained\n","    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU\n","    %cd ../\n","\n","!pip uninstall jax jaxlib -y\n","!pip install \"jax[cuda11_cudnn805]==0.3.10\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n","!pip install torch==1.8.1 torchvision==0.9.1\n","!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n","!pip install ninja\n","\n","%cd \"/content/drive/My Drive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\"\n","!git config --global user.name \"test\"\n","!git config --global user.email \"test@test.com\"\n","!git fetch origin\n","!git pull\n","!git stash\n","!git checkout origin/main -- train.py generate.py legacy.py closed_form_factorization.py flesh_digression.py apply_factor.py README.md calc_metrics.py training/stylegan2_multi.py training/training_loop.py util/utilgan.py"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"-MgOcCseZqlA"},"outputs":[],"source":["#@title 3. Compress our dataset into a zip file\n","#@markdown Write the directory of your Dataset.\n","\n","#@markdown **REMEMBER:** The image path must not contain spaces \" \", to avoid errors use a symbol instead \"_\"\n","input_dir = '/content/drive/MyDrive/data/gan01/images' #@param {type: \"string\"}\n","#@markdown Path to the *zip* file where the converted *Dataset* will be stored. You must create it the first time.\n","dataset_file = '/content/drive/MyDrive/data/gan01/verify.zip' #@param {type: \"string\"}\n","\n","if not dataset_file.endswith('.zip'):\n","  dataset_file += '.zip'\n","\n","!python dataset_tool.py --source {input_dir} --dest {dataset_file}"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"E25JTmDbZX1z"},"outputs":[],"source":["#@title 4. Custom Model Training\n","\n","#@markdown Enter the path to the *zip* file of the *Dataset*\n","dataset = \"/content/drive/MyDrive/data/gan01/verify.zip\" #@param {type: \"string\"}\n","\n","#@markdown For transfer learning, set it to **ffhq256**, **ffhq512** or **ffhq1024** according to the resolution of your images.\n","#@markdown If you want to resume the training process, please provide the path to your latest *.pkl* file\n","resume_from = \"ffhq512\" #@param {type: \"string\"}\n","\n","#don't edit this unless you know what you're doing :)\n","!python train.py --outdir ./results --snap=1 --cfg='11gb-gpu' --data={dataset} --aug=noaug --mirror=False --mirrory=False --metrics=None --resume={resume_from}"]},{"cell_type":"markdown","metadata":{"id":"GwPrEVh5coPf"},"source":["### While you are training...\n","Once the cell above is running, it should be training!\n","\n","Don't close this tab! Colab must be open and operational to continue training.\n","\n","Every 40 minutes or so a new line should be added to your output, indicating that you are still training. Depending on your snapshot_count settings, you should see the results folder (/content/drive/MyDrive/colab-sg2-ada/stylegan2-ada/results) in your Google drive folder filling up with both samples (fakesXXXXXx.jpg) and model weights (model weights) (network-snapshot-XXXXXX.pkl). It's worth looking at samples while training, but don't worry too much about each individual sample.\n","\n","Once Colab is powered off, you can plug it back into the housing and rerun each cell from top to bottom. Make sure to update the resume_from path to continue training from the latest model."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["GwPrEVh5coPf"],"machine_shape":"hm","provenance":[{"file_id":"https://github.com/angelv-salazar/visiones-posnaturales/blob/main/sg2_ada_pytorch_tensorV2.ipynb","timestamp":1701091704767}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}