{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/angelv-salazar/visiones-posnaturales/blob/main/preparaci%C3%B3n-datos.ipynb","timestamp":1701090508097},{"file_id":"https://github.com/angelv-salazar/escenarios-posnaturales/blob/main/preparaci%C3%B3n_datos.ipynb","timestamp":1654699918839}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"vzNwCqRMxvCo"},"source":["# Dataset Preparation (IMAGES)"]},{"cell_type":"code","metadata":{"id":"81nfc8JN2EBK","cellView":"form"},"source":["#@title 1. Import Libraries\n","#@markdown Libraries required for image manipulation\n","#|hide\n","#|skip\n","! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab\n","!apt install imagemagick > /dev/null 2>&1\n","\n","import glob\n","import os\n","from math import floor, ceil\n","from PIL import Image\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from fastai.vision.all import *\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"42K-qGO7q7I7","cellView":"form"},"source":["#@title 2. Define Functions\n","\n","#@markdown Image Manipulation Features\n","\n","def crop_center(img, ratio):\n","  img = img.copy()\n","  width, height = img.size\n","  crop_size= ceil(ratio * min(img.size))\n","\n","  left = (width - crop_size)/2\n","  top = (height - crop_size)/2\n","  right = (width + crop_size)/2\n","  bottom = (height + crop_size)/2\n","\n","  return img.crop((left, top, right, bottom))\n","\n","def save_crop(img, cnt, path, augment=False):\n","    img = img.copy()\n","\n","    img.save(f'{path}{cnt:08d}.png')\n","    cnt += 1\n","    if augment:\n","        img.transpose(Image.FLIP_LEFT_RIGHT).save(f'{path}/{cnt:08d}.png')\n","        cnt += 1\n","        img.transpose(Image.FLIP_TOP_BOTTOM).save(f'{path}/{cnt:08d}.png')\n","        cnt += 1\n","        img.transpose(Image.ROTATE_180).save(f'{path}/{cnt:08d}.png')\n","        cnt += 1\n","\n","    return cnt\n","\n","def thumbnail(img, size=256):\n","    \"\"\"\n","    resize image so smallest side will be equal to size\n","    \"\"\"\n","\n","    img = img.copy()\n","\n","    if img.mode not in ('L', 'RGB'):\n","        img = img.convert('RGB')\n","\n","    width, height = img.size\n","\n","    if width == height:\n","        img.thumbnail((size, size), Image.ANTIALIAS)\n","\n","    elif height > width:\n","        ratio = float(height) / float(width)\n","        newheight = ratio * size\n","        img = img.resize((size, int(floor(newheight))), Image.ANTIALIAS)\n","\n","    elif width > height:\n","        ratio = float(width) / float(height)\n","        newwidth = ratio * size\n","        img = img.resize((int(floor(newwidth)), size), Image.ANTIALIAS)\n","\n","\n","    return img\n","\n","def get_crop_bboxes(w, h):\n","    \"\"\"\n","    calculate bounding boxes based on width and height\n","    \"\"\"\n","    n_step = ceil(float(w) / float(h))\n","    shift = (w - h) // n_step\n","    shifting_array = []\n","    for step in range(0, n_step):\n","        if w > h:\n","            shifting = (shift * step, 0, shift * step + h, h)\n","        else:\n","            shifting = (0, shift * step, w, shift * step + w)\n","        shifting_array.append(shifting)\n","    if w > h:\n","        shifting = (w - h, 0, w, h)\n","    else:\n","        shifting = (0, h - w, w, h)\n","    shifting_array.append(shifting)\n","    return shifting_array"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MtszQjS01CYI","cellView":"form"},"source":["#@title 3. Mount Google Drive\n","#@markdown Access your Google Drive to load your Dataset, edit the images and save the results.\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AEkxxHEkxuFy","cellView":"form"},"source":["#@title 4. Crop the center of the images\n","#@markdown This cell will crop the center of each image in the input directory, resize it, and save the result to the output directory\n","\n","#@markdown Write the path of your dataset images directory:\n","input_dir = '/content/drive/MyDrive/Datasets/birdaus' #@param {type:\"string\"}\n","#@markdown Write the output directory. If it does not exist it will be created:\n","out_dir = '/content/drive/MyDrive/Datasets/birdaus-cort' #@param {type:'string'}\n","#@markdown Resize to:\n","resize = \"1024\" #@param [\"256\", \"512\", \"1024\"] {allow-input: true}\n","resize = int(resize)\n","#@markdown Cut size ratio. The size of the cut square will be equal to: \"proportion * size of the shortest side\". `ratio * min side size`\n","ratio = 1 #@param {type:\"slider\", min:0.1, max:1, step:0.05}\n","#@markdown Increase the Dataset with rotation. *Keep it **OFF** for this workshop*.\n","augment = False #@param {type:\"boolean\"}\n","\n","if out_dir[-1] != \"/\":\n","  out_dir += \"/\"\n","\n","if not os.path.exists(out_dir):\n","    os.makedirs(out_dir)\n","\n","images = glob.glob(f'{input_dir}/*.tif')+glob.glob(f'{input_dir}/*.png')+glob.glob(f'{input_dir}/*.jpg')+glob.glob(f'{input_dir}/*.bmp')\n","cnt=0\n","print(f'Cropping {len(images)} images\\n')\n","for image in tqdm(images):\n","  img = Image.open(image)\n","  cropped = crop_center(img, ratio)\n","  resized = cropped.resize((resize, resize), Image.ANTIALIAS)\n","  cnt=save_crop(resized, cnt, out_dir, augment)\n","print(f'Number of images saved: {cnt}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"djBeB_42yF0D","cellView":"form"},"source":["#@title 5. Fraction Images\n","\n","#@markdown If you have very large images, this cell will divide them into several square images, resize each image and save the result in the output directory\n","\n","#@markdown Write the path of your dataset images directory:\n","input_dir = '/content/drive/MyDrive/data/gan01/images-corte' #@param {type:'string'}\n","#@markdown Write the output directory. If it does not exist it will be created:\n","out_dir = '/content/drive/MyDrive/data/gan01/fraccion' #@param {type:'string'}\n","#@markdown Resize to:\n","resize = \"1024\" #@param [256, 512, 1024] {allow-input: true}\n","resize = int(resize)\n","#@markdown Increase the Dataset with rotation. Keep it OFF for this workshop.\n","augment = False #@param {type:\"boolean\"}\n","\n","if out_dir[-1] != \"/\":\n","  out_dir += \"/\"\n","\n","if not os.path.exists(out_dir):\n","    os.makedirs(out_dir)\n","\n","images = glob.glob(f'{input_dir}/*.tif')+glob.glob(f'{input_dir}/*.png')+glob.glob(f'{input_dir}/*.jpg')+glob.glob(f'{input_dir}/*.bmp')\n","cnt=0\n","print(f'Cropping {len(images)} images\\n')\n","for image in tqdm(images):\n","    img = Image.open(image)\n","    img = thumbnail(img, size=resize)\n","    w, h = img.size\n","    bboxes = get_crop_bboxes(w, h)\n","    for bbox in bboxes:\n","        img_cropped = img.crop(bbox)\n","        cnt = save_crop(img_cropped, cnt, out_dir, False)\n","print(f'Number of images saved: {cnt}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kJmepgICy1cG","cellView":"form"},"source":["#@title 6. Verify Images\n","#@markdown This cell will check the images in the input directory. Images will be resized to the defined size, converted to RGB and saved in the output directory.\n","\n","#@markdown Write the path of your cropped dataset images directory:\n","input_dir = '/content/drive/MyDrive/Datasets/birdaus-cort' #@param {type:'string'}\n","#@markdown Write the output directory. If it does not exist it will be created:\n","out_dir = '/content/drive/MyDrive/Datasets/birdaus-verify' #@param {type:'string'}\n","#@markdown Resize to:\n","resize = \"1024\" #@param [256, 512, 1024] {allow-input: true}\n","resize = int(resize)\n","\n","if out_dir[-1] != \"/\":\n","  out_dir += \"/\"\n","\n","if not os.path.exists(out_dir):\n","    os.makedirs(out_dir)\n","\n","images = glob.glob(f'{input_dir}/*.tif')+glob.glob(f'{input_dir}/*.png')+glob.glob(f'{input_dir}/*.jpg')+glob.glob(f'{input_dir}/*.bmp')\n","cnt=0\n","print(f'Verifying {len(images)} images\\n')\n","for image in tqdm(images):\n","    img = Image.open(image)\n","    img = img.resize((resize, resize), Image.ANTIALIAS)\n","    imgarr = np.array(img)\n","    img_channels = 1 if len(imgarr.shape) == 2 else imgarr.shape[2]\n","    if img_channels == 1:\n","      # print(imgarr.shape)\n","      R = np.stack((imgarr, imgarr, imgarr), axis=2)\n","      img = Image.fromarray(R, 'RGB')\n","      imgarr = np.array(img)\n","      # print(imgarr.shape)\n","    if img.mode in ('RGBA', 'LA') or (img.mode == 'P' and 'transparency' in img.info):\n","      bg = Image.new('RGB', img.size, (255, 255, 255))\n","\n","      bg.paste(img, (0, 0), img)\n","      img = bg\n","    img.save(f'{out_dir}{cnt:08d}.png')\n","    cnt+=1\n"],"execution_count":null,"outputs":[]}]}